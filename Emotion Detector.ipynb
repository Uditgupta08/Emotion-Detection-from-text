{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f5308d",
   "metadata": {},
   "source": [
    "# Emotion Detection Model\n",
    "This notebook demonstrates the process of building and evaluating an emotion detection model using machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb82e5",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a40f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udit0\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\udit0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\udit0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\udit0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import neattext.functions as nfx\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "import re \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08c713",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21175b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique training labels: [0 3 2 5 4 1]\n",
      "Unique validation labels: [0 2 3 1 4 5]\n",
      "Unique test labels: [0 1 4 3 2 5]\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_val = pd.read_csv(\"data/validation.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Check unique Emotions in each dataset\n",
    "print(\"Unique training labels:\", df_train['label'].unique())\n",
    "print(\"Unique validation labels:\", df_val['label'].unique())\n",
    "print(\"Unique test labels:\", df_test['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905aa266",
   "metadata": {},
   "source": [
    "## Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66389f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'sadness',\n",
    "    1: 'joy',\n",
    "    2: 'love',\n",
    "    3: 'anger',\n",
    "    4: 'fear',\n",
    "    5: 'surprise'\n",
    "}\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['emotion'] = df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a1b7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training set: text       0\n",
      "label      0\n",
      "emotion    0\n",
      "dtype: int64\n",
      "\n",
      "Training set emotion distribution:\n",
      " emotion\n",
      "joy         5362\n",
      "sadness     4666\n",
      "anger       2159\n",
      "fear        1937\n",
      "love        1304\n",
      "surprise     572\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for Missing values in training data\n",
    "print(\"Missing values in training set:\", df_train.isnull().sum())\n",
    "\n",
    "#Value counts of each Emotions\n",
    "print(\"\\nTraining set emotion distribution:\\n\", df_train['emotion'].value_counts())\n",
    "\n",
    "dir(nfx)\n",
    "df_train['Clean_Text'] = df_train['text'].apply(nfx.remove_userhandles)\n",
    "df_train['Clean_Text'] = df_train['Clean_Text'].apply(nfx.remove_stopwords)\n",
    "\n",
    "df_test['Clean_Text'] = df_test['text'].apply(nfx.remove_userhandles)\n",
    "df_test['Clean_Text'] = df_test['Clean_Text'].apply(nfx.remove_stopwords)\n",
    "\n",
    "df_val['Clean_Text'] = df_val['text'].apply(nfx.remove_userhandles)\n",
    "df_val['Clean_Text'] = df_val['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fce924",
   "metadata": {},
   "source": [
    "## Text Preprocessing with Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b07737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the stemmer\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# # Define a function for tokenization and stemming\n",
    "# def stemmed_tokenizer(text):\n",
    "#     tokens = nltk.word_tokenize(text)\n",
    "#     return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to get the Part of Speech (POS) for accurate lemmatization\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)  # Default to noun if POS not found\n",
    "\n",
    "# Define a function for tokenization and lemmatization\n",
    "def lemmatized_tokenizer(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016330d7",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d61cac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udit0\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the training data\n",
    "# vectorizer = CountVectorizer(tokenizer=lemmatized_tokenizer)\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(tokenizer=lemmatized_tokenizer, max_features=5000)\n",
    "\n",
    "tdm_train = vectorizer.fit_transform(df_train['Clean_Text'])\n",
    "tdm_val = vectorizer.transform(df_val['Clean_Text'])\n",
    "tdm_test = vectorizer.transform(df_test['Clean_Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730c780",
   "metadata": {},
   "source": [
    "## Training the Logistic Regression Model - OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a1a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# log_model_ovr = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "# log_model_ovr.fit(tdm_train, df_train['label'])\n",
    "\n",
    "# # Validate the model\n",
    "# y_val_pred_log_ovr = log_model_ovr.predict(tdm_val)\n",
    "\n",
    "# # Calculate and print validation accuracy\n",
    "# val_accuracy_log_ovr = accuracy_score(df_val['label'], y_val_pred_log_ovr)\n",
    "# print(\"Logistic Regression (OvR) Validation Accuracy:\", val_accuracy_log_ovr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class LogisticRegressionScratch:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000, regularization_strength=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        # Avoid overflow for large/small z\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def compute_loss(self, y, y_predicted):\n",
    "        # Binary cross-entropy loss with L2 regularization\n",
    "        num_samples = y.shape[0]\n",
    "        loss = (-1 / num_samples) * np.sum(\n",
    "            y * np.log(y_predicted + 1e-15) + (1 - y) * np.log(1 - y_predicted + 1e-15)\n",
    "        )\n",
    "        reg_loss = (self.regularization_strength / (2 * num_samples)) * np.sum(self.weights ** 2)\n",
    "        return loss + reg_loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.random.randn(num_features) * 0.01 \n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y)) + \\\n",
    "                 (self.regularization_strength / num_samples) * self.weights\n",
    "            db = (1 / num_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        return np.array([1 if i > 0.5 else 0 for i in y_predicted])\n",
    "\n",
    "class OneVsRestClassifier:\n",
    "    def __init__(self, base_classifier):\n",
    "        self.base_classifier = base_classifier\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_classes = len(np.unique(y))\n",
    "        self.models = []\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            binary_y = np.where(y == i, 1, 0)\n",
    "            model = LogisticRegressionScratch(\n",
    "                learning_rate=self.base_classifier.learning_rate,\n",
    "                num_iterations=self.base_classifier.num_iterations,\n",
    "                regularization_strength=self.base_classifier.regularization_strength\n",
    "            )\n",
    "            model.fit(X, binary_y)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([model.predict(X) for model in self.models]).T\n",
    "        return np.argmax(predictions, axis=1)\n",
    "\n",
    "# Prepare the data\n",
    "X_train = tdm_train.toarray()\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train the improved One-vs-Rest Logistic Regression model\n",
    "ovr_model = OneVsRestClassifier(\n",
    "    LogisticRegressionScratch(learning_rate=0.01, num_iterations=3000, regularization_strength=0.1)\n",
    ")\n",
    "ovr_model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "X_val = tdm_val.toarray()\n",
    "X_val = scaler.transform(X_val)\n",
    "y_val_pred = ovr_model.predict(X_val)\n",
    "\n",
    "# Calculate and print validation accuracy\n",
    "val_accuracy_ovr = accuracy_score(df_val['label'], y_val_pred)\n",
    "print(\"Improved One-vs-Rest Logistic Regression Validation Accuracy:\", val_accuracy_ovr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33fec8",
   "metadata": {},
   "source": [
    "## Training the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(tdm_train, df_train['label'])\n",
    "\n",
    "# Validate the Random Forest model\n",
    "y_val_pred_rf = rf_model.predict(tdm_val)\n",
    "\n",
    "# Calculate and print validation accuracy\n",
    "val_accuracy_rf = accuracy_score(df_val['label'], y_val_pred_rf)\n",
    "print(\"Random Forest Validation Accuracy:\", val_accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74767b2c",
   "metadata": {},
   "source": [
    "## Training the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train the SVM model\n",
    "# svm_model = SVC(probability=True,random_state=42)\n",
    "# svm_model.fit(tdm_train, df_train['label'])\n",
    "\n",
    "# # Validate the SVM model\n",
    "# y_val_pred_svm = svm_model.predict(tdm_val)\n",
    "\n",
    "# # Calculate and print validation accuracy\n",
    "# val_accuracy_svm = accuracy_score(df_val['label'], y_val_pred_svm)\n",
    "# print(\"SVM Validation Accuracy:\", val_accuracy_svm)\n",
    "\n",
    "base_svm_model = LinearSVC(random_state=42)\n",
    "svm_model = CalibratedClassifierCV(base_svm_model)\n",
    "svm_model.fit(tdm_train, df_train['label'])\n",
    "\n",
    "# Validate the calibrated model\n",
    "y_val_pred_svm = svm_model.predict(tdm_val)\n",
    "\n",
    "# Calculate and print validation accuracy\n",
    "val_accuracy_svm = accuracy_score(df_val['label'], y_val_pred_svm)\n",
    "print(\"Calibrated LinearSVC Validation Accuracy:\", val_accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711025f2",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd732e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(tdm_train, df_train['label'])\n",
    "\n",
    "# Validate the Naive Bayes model\n",
    "y_val_pred_nb = nb_model.predict(tdm_val)\n",
    "\n",
    "# Calculate and print validation accuracy\n",
    "val_accuracy_nb = accuracy_score(df_val['label'], y_val_pred_nb)\n",
    "print(\"Naive Bayes Validation Accuracy:\", val_accuracy_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79555730",
   "metadata": {},
   "source": [
    "## Training the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d91ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(tdm_train, df_train['label'])\n",
    "\n",
    "# Validate the Decision Tree model\n",
    "y_val_pred_dt = dt_model.predict(tdm_val)\n",
    "\n",
    "# Calculate and print validation accuracy\n",
    "val_accuracy_dt = accuracy_score(df_val['label'], y_val_pred_dt)\n",
    "print(\"Decision Tree Validation Accuracy:\", val_accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e1ac7",
   "metadata": {},
   "source": [
    "## Comparing Models and Testing the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = {\n",
    "    \"Logistic Regression\": val_accuracy_ovr,\n",
    "    \"Random Forest\": val_accuracy_rf,\n",
    "    \"SVM\": val_accuracy_svm,\n",
    "    \"Naive Bayes\": val_accuracy_nb,\n",
    "    \"Decision Tree\": val_accuracy_dt,\n",
    "}\n",
    "\n",
    "best_model_name = max(model_accuracies, key=model_accuracies.get)\n",
    "print(f\"The best model is {best_model_name} with accuracy: {model_accuracies[best_model_name]}\")\n",
    "\n",
    "best_model = {\n",
    "    \"Logistic Regression\": ovr_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"SVM\": svm_model,\n",
    "    \"Naive Bayes\": nb_model,\n",
    "    \"Decision Tree\": dt_model,\n",
    "}[best_model_name]\n",
    "y_test_pred = best_model.predict(tdm_test)\n",
    "test_accuracy = accuracy_score(df_test['label'], y_test_pred)\n",
    "print(f\"Test Accuracy with {best_model_name}: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b5021",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report and confusion matrix for the test dataset\n",
    "print(\"\\nClassification Report for the Test Dataset:\")\n",
    "print(classification_report(df_test['label'], y_test_pred))\n",
    "print(\"\\nConfusion Matrix for the Test Dataset:\")\n",
    "print(confusion_matrix(df_test['label'], y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ee54c",
   "metadata": {},
   "source": [
    "## Adding Predictions to the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted emotions to the test dataframe\n",
    "df_test['predicted_emotion'] = [\n",
    "    label_mapping[label] if label in label_mapping else 'unknown'\n",
    "    for label in y_test_pred\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466d394",
   "metadata": {},
   "source": [
    "## Displaying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the predictions in the test dataset\n",
    "print(\"\\nTest Dataset Predictions:\")\n",
    "print(df_test[['text', 'emotion', 'predicted_emotion']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b00f3",
   "metadata": {},
   "source": [
    "## Predicting Emotion Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57913b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(sentence, model, vectorizer, label_mapping):\n",
    "    sentence_tdm = vectorizer.transform([sentence])\n",
    "    probabilities = model.predict_proba(sentence_tdm)[0]\n",
    "    emotions = [label_mapping[i] for i in range(len(probabilities))]\n",
    "    \n",
    "    # Plot the predicted probabilities\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x=emotions, y=probabilities)\n",
    "    plt.title('Emotion Prediction')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c899a5",
   "metadata": {},
   "source": [
    "## Using the Predict Emotion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe36ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict emotion for a specific sentence\n",
    "# predict_emotion(\"I heard strange noises outside last night, and I couldn't sleep at all. My heart was racing, and I kept imagining all sorts of dangers lurking in the dark.\", best_model, vectorizer, label_mapping)\n",
    "\n",
    "# Function for user input prediction\n",
    "def user_input_prediction(model, vectorizer, label_mapping):\n",
    "    try:\n",
    "        sentence = input(\"Please enter a sentence to predict emotion: \")\n",
    "        predict_emotion(sentence, model, vectorizer, label_mapping)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the user input function\n",
    "user_input_prediction(best_model, vectorizer, label_mapping)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
